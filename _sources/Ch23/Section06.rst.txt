Section 06: Error Detection Algorithm
:::::::::::::::::::::::::::::::::::::

.. youtube:: kfp6yS0gFUM
        :height: 315
        :width: 560
        :align: left

Here is an algorithm for error defined. What elements in an agent's classification knowledge may be potentially responsible for his failure? Let us look at the problem where we define the false success elements. I just said earlier. Potentially, the agent may deceive a set of positive experiences, and a set of negative experiences, not just one positive or one negative. First the intersection of all of the features that are responsible for all the false successes. A false success again is, something that we already fine a success. What was not a success like the pill, we identified it as a cup, it was not a cup. First take the intersection of all the features present for all the false successes. False-success is an object where the agent identified as a success, but in fact was false. Like the pale. The agent identified that it was a cup, but it wasn't. Then take the union of the features present for all the true successes. A true success is something that the agent classified as a success, and indeed was a success. Now remove all the assertions of the union of the true successes, from the intersection of the false successes, to identify those elements that are present in the false successes only. So, to put that differently, start off by gathering together anything that's ever present in a false success. Then, gather together everything that's true for every single true success. Remove the things that are true for every true success, from the things that are ever true for any false success. That way we get a list of only the things that are true for some false successes. So we're defining suspicious true success relationships, except that here, the operations are in reverse. So similarly, here we gather together everything that's ever true about any true success, and then gather together things that are true for every single false success. So every single false example has these things in common. Then we remove the things that every single fault example has in common, from the things that are true for any true example. As you can see, we are taking unions and intersections of features characterizing different examples. The number of examples, both positive and negative, needed for this algorithm to work well, depends on the complexity of the concept. In general, the more features you have the description of the object, more will be the number of examples we'll need, to identify the features that were responsible for our failure.

