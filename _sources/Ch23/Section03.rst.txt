Section 03: Exercise Identifying a Cup
::::::::::::::::::::::::::::::::::::::

.. youtube:: Q4_YmFR9exE
        :height: 315
        :width: 560
        :align: left

Let us build on David's answers, let us suppose that the robot goes to the kitchen and finds this pail in the kitchen. It looks the pail and decides that this pail meets this definition of a cup, denoted here by the solid circle. The robot brings water to you in this pail. You look at the pail, and you say to the robot, no robot, this is not a cup. At this point you would expect a robot to learn from its failure. Cognitive agents do a lot of learing from failures. Failures are opportunities for learning. We would expect robots, and intelligent agents more generally, to learn from their failures as well. How then may a robot learn form the failure of considering this fail as a cup. Note that the problem is not limited to this particular fail. We can take a different example connecting with this particular cup. Imagine that the definition of cup included a statement that it must have a handle. In which case, the robot may not recognize that this is a cup. Later on you may teach the robot, this in fact is a good example for cup, because it's liftable. In that case, the robot will want to understand from that failure. It will want to understand why did it not consider it to be a cup? It should have considered it to be a cup. So the problem is not just about successes that turned out to be failures. But also about failures that should have been successes.

