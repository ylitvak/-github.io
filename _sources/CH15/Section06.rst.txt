Section 06: Thematic Roles and Primitive Actions
::::::::::::::::::::::::::::::::::::::::::::::::::
.. youtube:: IdpWlJskfNo
        :height: 315
        :width: 560
        :align: left

.. image:: ../../_static/Ch15/Slide06.png
        :height: 200px
        :width: 350px
        :alt: Class Goals
        :align: center

So let’s dig deeper into, how the agent may do the processing using this primitive action. So, consider the sentence John pushed the cart. The AI agent beings left to right, because we’re talk- ing about English language here. He first word here John is not a verb. So, the AI agent for the time being, puts this in a list of concepts. And ignores it it comes to the second word in the sentence. Which is pushed, there’s a word here, pushed, and now the AI agent uses this particular verb, push, as a probe into it’s longterm memory. So now, the frame for propel is going to get pulled out, let’s see what the frame would look like. So, here is the frame for propel that has been pulled out of the longterm memory? And this frame tells us that we can expect an agent. We can expect an object. And indeed, although we are not shown here, this frame may have additional slots and perhaps additional things can be expected. Now for each of the slots, there is a rule budding in here. A rule which tells us, how can we pull out from a sentence, the entity that goes under the slot? The filler that must go here. So here’s a rule that says that. If there is a concept just before the word, and that concept is animate, then, whatever that concept is, put it here. Well, there is a concept just before push, that’s John, and let’s suppose we have a lexicon which tells us if John is animate, then we put John here. Similarly there is a rule here for this slot, which tells the agent that if there is a object, there is a concept that comes after this verb. And that particular concept refers to an object that is inanimate. Then, take that particular thing, and put it here, and that’s the cart. And so, we put cart here. So this way, this particular scheme, helps us derive the meaning of, John pushed the cart. And notice that the processing is a combination of bottom up and top down, as we discussed earlier. It begins, bot- tom up. Because we are looking at the data. Right now we don’t have knowledge. But, as soon as some data is processed, it pulls in knowledge from memory. And soon the processing be- comes top down, this frame helps to general expectations. And help pull things out. This is almost acting, like a hook for a fish. So once you have the hook, then you can capture the fish well. There are several things to be noted here. First representations like this. First, representations like this, are called structure knowledge representations. There’s not only a representation here, but, there is a strong structure to it. Earlier when we were discussing predicates and logic, or we discussing rules and antecedents and consequence of rules. They are like the atoms of knowledge representation. They don’t have much structure. But by now, we have this molecule of forms knowledge representation. And which a large number of atoms are getting connected with each other. And this connections are important, because once you have that structure of the molecule it tells you what can go in the place of each atom. Second, this is a simple sentence, and so the processing was quite simple. The sentences need not always be as simple as this one. What happened to the sentence had the word, push in it? And I picked a frame, that is not the right frame for it. Suppose I had pulled out a frame for move object is shown as propel here. Well, one possibility is, that if you were to select a different frame for making sense of this particular sentence, there’s a high I try to fill the slot for this particular frame, I will find a lot of difficulty. In which case, I might abandon the frame and try a different one. The second possibility is, that I may even force the interpretation of this into the slots for the other frame. But, if there is a study here which contains large number of sentences then, soon I’ll realize this is not the right frame, I may abandon it and pick different frame. So for complex sentences, this processing is not as linear as we have pretended it to be right here. It is also possible, that sometimes one of the words en-map into two frames equally well. Indeed, this is the basis of many of the [puns] we encounter. So consider, I was wondering why the ball was becoming bigger. Then it hit me. Now, you of course understand the word hit there, that particular word, maps into two different interpretations, and that’s why it is interesting and funny. So here’s another one. Two men walk to the bar to, the third one ducks. Now here the word, the bar is overloaded. So here, walked into the bar, is getting interpreted two different ways. Indeed, people have tried to build accounts of humor, based on the kinds of story interpretation that we are doing here. Could it be, that this is beginning of a theory of humor. Of how you can tell stories not only to your machines?