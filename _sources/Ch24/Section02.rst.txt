Section 02: Mistakes in Reasoning and Learning
::::::::::::::::::::::::::::::::::::::::::::::

.. youtube:: 2b69KeRJ4RA
        :height: 315
        :width: 560
        :align: left

We have come across the notion of meta-reasoning earlier in this class. You may recall this was the explanation that an agent had built, to decide why a particular object was an instance of the cup. And we told it that it was an incorrect decision. The agent then, reflected on its knowledge. Here was the knowledge. Here was the explanation it had built. It is now reflecting on it and trying to figure out what makes this particular explanation incorrect. Where does the fault lie? That was an example where the agent was reflecting on its knowledge, but has this knowledge was stored in the short term memory. It had been pulled out of the long term memory. But just like there can be error in the knowledge, there could also potentially be an error in reasoning. Or potentially an error in the learning process. An example of an error in reasoning occurred very early in this particular class. You may recall this particular diagram from mean sense analysis. This was the blocks micro build. The agents needed to take the blocks from this initial stage to this goal state. However there were multiple goals here. D on table, C on D, B on C. And as the agent tried to accomplish these goals. It ran into cul de sacs, where no further progress was possible without undoing some of the earlier goals. So, that was an example of metacognition over reasoning, where the agent was trying to figure out, what was the error in my reasoning, and how can I remedy it. We can similarly have metacognition over learning. So an example of metacognition where learning occurred. When we were talking about learning making mistakes. You recall this was the explanation the agent had built, after it had remedied the explanation. The remedy in this particular case was adding here that the handle is fixed and relating it to the rest of the explanation. Given that the agent had used explanation based learning to build this explanation in the first place, we can think of the agent as, reflecting on this process of explanation based learning and asking itself, what did I do wrong? And then deciding, well I built the wrong explanation. I must change that explanation. And that's what learning by correcting mistakes did. We can consider this to be a process of metacognition of learning in the sense that the agent may say, how did I learn this particular knowledge. Well, they learned it through explanationless learning. So what was wrong in my process of explanationless learning that lead to this incorrect explanation? How do I fix my process of explanationless learning so that I do not make the same error, again?

