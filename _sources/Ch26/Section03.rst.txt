Section 03: Course Structure Revisited
::::::::::::::::::::::::::::::::::::::

.. youtube:: g7KAUwkGMPo
        :height: 315
        :width: 560
        :align: left

We have covered a fairly large number of topics in this course. You might recall this particular chart from the first lesson. Let us go through each one of these circles one-by-one and see the connections between them. So, in the fundamentals, we covered knowledge representations like semantic networks. In fact, we used semantic networks to address two-by-one matrix problems. Then we covered a series of problem solving methods. There's already domain independent journal purpose methods. They do not use a lot of knowledge, but they're very powerful, generate and test, means-ends analysis, and problem reduction. Then we turn to production systems. They are a specific kind of cognitive architecture. Production systems combine reasoning, learning, and memory. Production systems to bolster technology for developing agents, and a theory of human computation. Later we talked about planning. And in order to talk about planning we first proposed a formal language for discussing the plan. It's called formal logic. We learned about the different rules and syntax used for writing formula logical statements. And learned why this is very important, that it allows agents to prove the accuracy of their conclusions based on a set of axioms. That gave us a language that we could then use to talk about planning, and as we found out actually, the origins of planning where an agent's making proofs of why a certain set of actions would lead to a certain goal. Here we talked about both partial order planning and hierarchical planning, which are two planning methods that allow agents to make advanced plans for complex tasks. And also allows us to reflect on the way we ourselves plan our actions to complex environments. Under common sense reasoning we covered several important lessons. Frames, understanding, common sense reasoning and scripts. Frames is a structured knowledge to that allows us to do understanding. Understanding is such a common every day activity. We are trying to make sense of the world, but the world is ambiguous. The word, take, for example can have so many different meanings. We saw how frames allow us to disambiguate different meanings of the word take. Under common sense reasoning we made every day intuitive inferences about the world around us. With understanding and common sense reasoning, we're concerned with sentence-level understanding. Scripts is more concerned about discourse-level understanding. Scripts is an even larger, just structure knowledge presentation than frames. It, too allows us to make sense of the world around us, both the physical world and the social world. Frames also came up in some of the other lessons, and particularly came up in the lesson on production systems, when we were trying to represent episodic knowledge. It also came up in the lesson on configuration, when we were trying to represent plans, and the variables of various plans that can take values. We talked about learning in many lessons throughout this course. But certain lessons were explicitly and solely concerned with learning. We started off by talking about learning by recording cases, where an agent could build up a case library of its own prior experiences to use for future reasoning. That formed a foundation of analogical reasoning as well, that we'll talk about in a second. We also talked about incremental concept learning and version spaces, two different learning methods for learning about information that's coming in incrementally, or bit by bit. That was one of our foundational principles of this class that we discussed at the beginning and that we'll revisit in a few minutes. We also talked about classification under learning, which is one of the most ubiquitous problems in AI. We talked about how classification involves grouping large combinations of percepts into equivalence classes, to allow for easier action selection. Learning also can open several other lessons that we did throughout this class, including production systems, key spaced reasoning, explanation based learning, analogical reasoning, and learning about correcting mistakes. Metareasoning was also deeply connected to learning, where we could learn from our own experiences by analyzing our own prior thought processes. As David just said, analogical reasoning is another major topic connected with learning. We talked about learning by recording cases. We are simply assimilating cases by recording them in a growing case library. As a new problem comes, we use methods like nearest neighbor to retrieve the closest case, and it invoked that case with a new problem. We talked about case-based reasoning, in which we not only retrieved the case, but we also tweak it, or modify it in small ways in order to achieve a new goal. In explanation-based learning, we saw how we could connect instances to kinds of definitions. We constructed explanations that told us how instance is an example of a given concept. This involved both abstraction and transfer. We also connected explanation-based learning to creativity. Analogical reasoning made [INAUDIBLE] abstraction and transfer even more explicit. We talked about cross analogical transfer for example from the solar system to the atomic structure. We saw that when needed, rich mental models in order to be able to do an analogical transfer. We concluded the lesson on analogical reasoning by connecting it with analogical design or design by analogy. And analogical reasoning too is closely connected to creativity. Our discussion of visuospatial reasoning started with our unit on constraint propagation. Constraint propagation was a very abstract and general way of propagating constraints to make sense of a new situation, and it comes up uniquely in visual reasoning. Or we use line labeling to make sense of 3D scenes even if they're presented in 2D. Where we use line labeling to make sense of three dimensional scenes even if they're presented in only two dimensions. We also how constraint propagation can be used for natural language understanding. And we referenced how we might also use it to understand music or tactile information. Then in visuospatial reasoning we expanded on these notions to discuss whether it would be possible to reason about the world without extracting propositions. This involved looking at scenes in the world where there was no explicit causality, like a glass that's been spilled on the table. We can infer what happened, but there's nothing in the visual scene that tells us exactly how it arose. Similarly, we also discuss how this could apply to other modalities, like tactile information or musical information. In the unit on design and creativity, we considered lessons in configuration, diagnosis, design and creativity. You may recall that in configuration, we were worried about very routine, everyday kind of designs, and we did that kind of design by having a library of clients at different levels of abstraction. We selected a plan at a high level of abstraction, assign values to some of the variables, and then refine the plan at the next door level abstraction. All the components were known, we had to decide on the arrangement of the components of configuration. In diagnosis, we were given data about a malfunctioning system and we had to identify the fault responsible for that malfunctioning. We took two views of diagnosis, classification and abduction. In the classification view, this data was mapped into equal classes that acted like hypotheses for this data. In abduction, we composed this elementary hypothesis into a composite hypothesis that could best explain the entire data. Design thinking refers to thinking about problems that are ill-defined and open-ended, and under-constrained. In design thinking, the problem and solution often co-evolve. The problem doesn't remain fixed. The solution evolves, but that in turns it leads to improving the understanding of the problem, both our understanding of the problem and solution evolve together. We cut across creativity in terms of novelty, value, and the non-obviousness of the results. We discuss the criteria under which we would consider an agent to be creative. And we saw how many of the techniques that you have learned in this particular class can compose the fundamental processes of creativity. Like analogical reasoning, like visual special reasoning, like meta-reasoning. Then we close the class by talking about meta-cognition. Meta-cognition enable the agents to reason about their own reasoning, or think about their own thinking, or have knowledge of their own knowledge base. We started out by talking about learning by correcting mistakes. Or an agent can look at a mistake that's been made in the past, isolate the mistake, explain the mistake and then fix the mistake so that it didn't happen again. This was one narrow instance of the broader idea of meta-reasoning. In meta-reasoning, we talked about metacognition could bring together many of the different methods that we talked about throughout this class. Meta-reasoning enabled an agent to look at a new problem and select which of its many strategies would be best for addressing that problem. It also would allow an agent to integrate multiple different methods of reasoning at different levels of distraction. We also talked about what how meta-reasoning operates is also the way in which meta-reasoning operates. Meta-reasoning can reason about case based reasoning, or it can reason using case based reasoning. It could, for example, use production rules to conduct case based reasoning. In this way it could integrate many different methods at many different levels of instruction. Finally, this set up a notion of ethics in artificial intelligence. As we're building AI agents that are starting to have real, human level intelligence, what are the ethical issues? What should we think about replacing certain human jobs with robots, or what should we think about developing robots that can interact with us on an everyday basis in the natural world? Under what conditions would we consider these agents to actually be human-like? This summarizes 30 topics that we covered in this class, which is quite a lot. Of course, there is a lot more to talk about each of these 30 topics than we have covered so far. Therefore we have provided readings for each of the topics. And you are welcome to pursue the readings for whatever topic that interests you the most. We would also love to hear about your views about this on the forum.

