Section 29: Final Concept of a Foo
::::::::::::::::::::::::::::::::::

.. youtube:: T21gCLSN5RM
        :height: 315
        :width: 560
        :align: left

So, given the input series of examples, and the background knowledge, this is the final concept definition for [UNKNOWN] that this particular [UNKNOWN] agent will learn. Notice, that there are no must support lengths here, because input [UNKNOWN] of examples did not require them. Now it is also, that we did not generalize this bricks into something else, or further generalize these blocks into something else, because there was no background knowledge to do that. So the result of learning here, depends not just on the input examples, but on the background knowledge that the AI agent has. This method of incremental concept learning differs quite a bit from some of these standard algorithms in machine learning. Often in machine learning, the AI agent is a given a large number of examples to begin with and the learning begins with those large number of examples where the number of examples could be in thousands or millions or more. When you have a large number of examples to begin with, then one can apply statistical machine learning methods to find patterns of regularity in the input data. But if the number of examples is very small, and if the examples come one at a time, the learning is incremental. Then it becomes harder to apply those statistical methods to detect patterns of the [INAUDIBLE] input data. Instead, in that case, the algorithm must make use of its background knowledge to decide what to learn and how to learn it.

